{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597321890746",
   "display_name": "Python 3.8.5 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSearch(X, labels, function, cost_func, num_epochs, _range, n_features):\n",
    "    best_weights = None \n",
    "    best_bias = None \n",
    "    lowest_cost = float('inf') # initialize it very high\n",
    "    # try num_epochs many different randomised parameterisations\n",
    "    for i in range(num_epochs):\n",
    "        w = np.random.randn(-_range, _range, n_features) \n",
    "        b = np.random.randn(-_range, _range) \n",
    "        # print(w, b)\n",
    "        y_hat = function(X, w, b) # make prediction\n",
    "        cost = cost_func(y_hat, labels) # calculate loss\n",
    "        # if it is the best parameterisation so far then store the weight and bias\n",
    "        if cost < lowest_cost:\n",
    "            lowest_cost = cost \n",
    "            best_weights = w \n",
    "            best_bias = b\n",
    "    print('Lowest cost of', lowest_cost, 'achieved with weight of', best_weights, 'and bias of', best_bias)\n",
    "    return best_weights, best_bias \n",
    "\n"
   ]
  }
 ]
}